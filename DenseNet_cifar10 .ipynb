{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "wVIx_KIigxPV",
    "outputId": "3ff61830-3199-429b-ce8d-43a5a4e6d8f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import keras\n",
    "# from keras.datasets import cifar10\n",
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "# from keras.layers import Concatenate\n",
    "# from keras.optimizers import Adam\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNHw6luQg3gc"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "l = 40\n",
    "num_filter = 12\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mB7o3zu1g6eT",
    "outputId": "66b87396-d698-4aeb-8729-5fc3f3934742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 Data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3lAk_Mw_5-rn",
    "outputId": "2139e601-c8c9-42e0-ff7d-57d6cad37358"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DVkpgHsc5-rp",
    "outputId": "be340b62-9155-4159-9ae3-0747d46f90ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Blosck\n",
    "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anPCpQWhhGb7"
   },
   "outputs": [],
   "source": [
    "\n",
    "num_filter = 12\n",
    "dropout_rate = 0.2\n",
    "l = 12\n",
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c5Wksy8z5-rw",
    "outputId": "242f1c0a-2e46-42e2-f417-57747f5f4e69"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/-W6y8xnd--U\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0xd19d55f60>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://arxiv.org/pdf/1608.06993.pdf\n",
    "from IPython.display import IFrame, YouTubeVideo\n",
    "YouTubeVideo(id='-W6y8xnd--U', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1kFh7pdxhNtT",
    "outputId": "b266ecf6-8ed9-4971-c83a-a2a840226674",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 12)   324         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 12)   48          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 12)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 6)    648         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 6)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 18)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 18)   72          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 18)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 6)    972         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 6)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 24)   0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 24)   96          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 24)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 6)    1296        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 6)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 30)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 30)   120         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 30)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 6)    1620        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 6)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 36)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 36)   144         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 36)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 6)    1944        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 6)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 42)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 42)   168         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 42)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 6)    2268        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 6)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 48)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 6)    2592        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 6)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 54)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 54)   216         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 54)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 6)    2916        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 6)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 60)   0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 60)   240         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 60)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 6)    3240        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 6)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 66)   0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 66)   264         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 66)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 6)    3564        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 6)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 72)   0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 72)   288         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 72)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 6)    3888        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 6)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 78)   0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 78)   312         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 78)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 6)    4212        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 6)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 84)   0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 84)   336         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 84)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 6)    504         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 6)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 6)    0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 6)    24          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 6)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 6)    324         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 6)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 12)   0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 12)   48          concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 12)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 6)    648         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 6)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 18)   0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 18)   72          concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 18)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 6)    972         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 6)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 24)   0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 24)   96          concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 24)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 6)    1296        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 6)    0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 30)   0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 30)   120         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 30)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 6)    1620        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 6)    0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 36)   0           concatenate_15[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 36)   144         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 36)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 6)    1944        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 6)    0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 42)   0           concatenate_16[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 42)   168         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 42)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 6)    2268        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 6)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 48)   0           concatenate_17[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   192         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 6)    2592        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 6)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 54)   0           concatenate_18[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 54)   216         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 54)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 6)    2916        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 6)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 60)   0           concatenate_19[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 60)   240         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 60)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 6)    3240        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 6)    0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 66)   0           concatenate_20[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 66)   264         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 66)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 6)    3564        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 6)    0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 72)   0           concatenate_21[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 72)   288         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 72)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 6)    3888        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 6)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 78)   0           concatenate_22[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 78)   312         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 78)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 6)    468         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 6)    0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 6)      0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 6)      24          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 6)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 6)      324         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 6)      0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 12)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 12)     48          concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 12)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 6)      648         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 8, 8, 6)      0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 18)     0           concatenate_24[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 18)     72          concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 18)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 6)      972         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 8, 8, 6)      0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 24)     0           concatenate_25[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 24)     96          concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 24)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 6)      1296        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 8, 8, 6)      0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 30)     0           concatenate_26[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 30)     120         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 30)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 6)      1620        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 8, 8, 6)      0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 36)     0           concatenate_27[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 36)     144         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 36)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 6)      1944        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 8, 8, 6)      0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 42)     0           concatenate_28[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 42)     168         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 42)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 6)      2268        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 8, 8, 6)      0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 48)     0           concatenate_29[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 48)     192         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 48)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 6)      2592        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 8, 8, 6)      0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 54)     0           concatenate_30[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 54)     216         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 54)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 6)      2916        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 8, 8, 6)      0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 60)     0           concatenate_31[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 60)     240         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 60)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 6)      3240        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 8, 8, 6)      0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 66)     0           concatenate_32[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 66)     264         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 66)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 6)      3564        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8, 8, 6)      0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 72)     0           concatenate_33[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 72)     288         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 72)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 6)      3888        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 8, 8, 6)      0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 78)     0           concatenate_34[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 78)     312         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 78)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 6)      468         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 8, 8, 6)      0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 6)      0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 6)      24          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 6)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 4, 6)      324         activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 4, 4, 6)      0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 12)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 12)     48          concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 12)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 4, 6)      648         activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 4, 4, 6)      0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 18)     0           concatenate_36[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4, 18)     72          concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 18)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 4, 6)      972         activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 4, 4, 6)      0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 24)     0           concatenate_37[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 24)     96          concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 24)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 4, 4, 6)      1296        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 4, 4, 6)      0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 30)     0           concatenate_38[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 30)     120         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 30)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 4, 4, 6)      1620        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 4, 4, 6)      0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 36)     0           concatenate_39[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 36)     144         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 36)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 4, 4, 6)      1944        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 4, 4, 6)      0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 42)     0           concatenate_40[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 42)     168         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 42)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 6)      2268        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 4, 4, 6)      0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 48)     0           concatenate_41[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 48)     192         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 48)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 6)      2592        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 4, 4, 6)      0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 54)     0           concatenate_42[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 54)     216         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 54)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 6)      2916        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 4, 4, 6)      0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 60)     0           concatenate_43[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 60)     240         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 60)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 6)      3240        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 4, 4, 6)      0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 66)     0           concatenate_44[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 66)     264         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 66)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 6)      3564        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 4, 4, 6)      0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 72)     0           concatenate_45[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 72)     288         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 72)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 6)      3888        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 4, 4, 6)      0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 78)     0           concatenate_46[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 78)     312         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 78)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 78)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 312)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           3130        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 118,918\n",
      "Trainable params: 114,394\n",
      "Non-trainable params: 4,524\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4XOsW3ahSkL"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "crhGk7kEhXAz",
    "outputId": "ba390596-c12e-4a35-fc3c-21864a121810",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 66s 1ms/sample - loss: 1.5326 - acc: 0.4339 - val_loss: 1.7971 - val_acc: 0.3777\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 63s 1ms/sample - loss: 1.3113 - acc: 0.5198 - val_loss: 1.5268 - val_acc: 0.4811\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 63s 1ms/sample - loss: 1.1942 - acc: 0.5669 - val_loss: 1.2360 - val_acc: 0.5562\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 63s 1ms/sample - loss: 1.1025 - acc: 0.6053 - val_loss: 1.1624 - val_acc: 0.5958\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 63s 1ms/sample - loss: 1.0459 - acc: 0.6238 - val_loss: 1.2096 - val_acc: 0.5858\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 63s 1ms/sample - loss: 0.9942 - acc: 0.6443 - val_loss: 1.1280 - val_acc: 0.6099\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.9592 - acc: 0.6570 - val_loss: 1.0519 - val_acc: 0.6422\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 63s 1ms/sample - loss: 0.9149 - acc: 0.6730 - val_loss: 0.9730 - val_acc: 0.6655\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.8915 - acc: 0.6814 - val_loss: 1.1207 - val_acc: 0.6436\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.8643 - acc: 0.6907 - val_loss: 0.9504 - val_acc: 0.6701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe423c45780>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcWydmIVhZGr"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UE3lF6EH1r_L",
    "outputId": "5a7f29df-cce2-4736-e772-35221c0b8e65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "model.save_weights(\"DNST_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46kReyaqfkig"
   },
   "source": [
    "<h3>CNN on CIFR Assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EXf2EG2Lfkii",
    "outputId": "12e53268-6771-4586-c53b-2eb3808b09cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[145, 153, 154]]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1:2,1:2,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Srxj8_Xdfkim"
   },
   "source": [
    "Dataset is not normalized ,need to normalize the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "40GM8QU8fkio",
    "outputId": "3ab7f623-870f-42a5-b8d9-60d3730fd6c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max(),X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2dK5UHwvfkis",
    "outputId": "fb2f92f1-9945-4732-d929-c96ceab7ed86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.56862745, 0.6       , 0.60392157]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X => (X - Xmin)/(Xmax-Xmin) = X/255\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "X_train[1:2,1:2,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5CizUT2c1G1"
   },
   "source": [
    "2 .created a copy of DenseNet<br>\n",
    "\n",
    "3 .Removed Dense Layers abd DropOut layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p3ORJfXcc-qY"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OnlfagECfkix"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "#Remove dropout layer by setting dropout_rate = 0\n",
    "def denseblock_1(input, num_filter = 12, dropout_rate = 0):\n",
    "  global compression\n",
    "  temp = input\n",
    "  for _ in range(l):\n",
    "    BatchNorm = layers.BatchNormalization()(temp)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "      Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "    concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "    temp = concat\n",
    "        \n",
    "  return temp\n",
    "\n",
    "## transition Blosck\n",
    "#Remove dropout layer by setting dropout_rate = 0\n",
    "def transition_1(input, num_filter = 12, dropout_rate = 0):\n",
    "  global compression\n",
    "  BatchNorm = layers.BatchNormalization()(input)\n",
    "  relu = layers.Activation('relu')(BatchNorm)\n",
    "  Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "  if dropout_rate>0:\n",
    "    Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "  avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "  return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer_1(input):\n",
    "  global compression\n",
    "  BatchNorm = layers.BatchNormalization()(input)\n",
    "  relu = layers.Activation('relu')(BatchNorm)\n",
    "  AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "  conv=layers.Conv2D(num_classes, kernel_size = (2,2))(AvgPooling)\n",
    "  output = Activation('softmax')(conv)\n",
    "\n",
    "  #output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "  # got error as mentioned \"A target array with shape (50000, 10) was passed for an output of shape (None, 1, 1, 10)\" so added flatten layer at the end\n",
    "  output = Flatten()(output)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qj6hrgKA0Xqo"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "num_filter = 36\n",
    "dropout_rate = 0\n",
    "l = 12\n",
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock_1(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition_1(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = denseblock_1(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition_1(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = denseblock_1(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition_1(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = denseblock_1(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer_1(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "S-YfYrp91kfi",
    "outputId": "bc28e30a-cdbd-438c-a2c6-38af8a52a485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 36)   972         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 36)   144         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 36)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 18)   5832        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 54)   0           conv2d[0][0]                     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 54)   216         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 54)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 18)   8748        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 72)   0           concatenate[0][0]                \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 72)   288         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 72)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 18)   11664       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 90)   0           concatenate_1[0][0]              \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 90)   360         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 90)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 18)   14580       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 108)  0           concatenate_2[0][0]              \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 108)  432         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 108)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 18)   17496       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 126)  0           concatenate_3[0][0]              \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 126)  504         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 126)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 18)   20412       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 144)  0           concatenate_4[0][0]              \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 144)  576         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 144)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 18)   23328       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 162)  0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 162)  648         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 162)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 18)   26244       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 180)  0           concatenate_6[0][0]              \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 180)  720         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 180)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 18)   29160       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 198)  0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 198)  792         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 198)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 18)   32076       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 216)  0           concatenate_8[0][0]              \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 216)  864         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 216)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 18)   34992       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 234)  0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 234)  936         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 234)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 18)   37908       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 252)  0           concatenate_10[0][0]             \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 252)  1008        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 252)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 18)   4536        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 18)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 18)   72          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 18)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 18)   2916        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 36)   0           average_pooling2d[0][0]          \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 36)   144         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 36)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 18)   5832        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 54)   0           concatenate_12[0][0]             \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 54)   216         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 54)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 18)   8748        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 72)   0           concatenate_13[0][0]             \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 72)   288         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 72)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 18)   11664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 90)   0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 90)   360         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 90)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 18)   14580       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 108)  0           concatenate_15[0][0]             \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 108)  432         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 108)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 18)   17496       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 126)  0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 126)  504         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 126)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 18)   20412       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 144)  0           concatenate_17[0][0]             \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 144)  576         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 144)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 18)   23328       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 162)  0           concatenate_18[0][0]             \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 162)  648         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 162)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 18)   26244       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 180)  0           concatenate_19[0][0]             \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 180)  720         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 180)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 18)   29160       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 198)  0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 198)  792         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 198)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 18)   32076       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 216)  0           concatenate_21[0][0]             \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 216)  864         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 216)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 18)   34992       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 234)  0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 234)  936         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 234)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 18)   4212        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 18)     0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 18)     72          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 18)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 18)     2916        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 36)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 36)     144         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 36)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 18)     5832        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 54)     0           concatenate_24[0][0]             \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 54)     216         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 54)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 18)     8748        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 72)     0           concatenate_25[0][0]             \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 72)     288         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 72)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 18)     11664       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 90)     0           concatenate_26[0][0]             \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 90)     360         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 90)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 18)     14580       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 108)    0           concatenate_27[0][0]             \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 108)    432         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 108)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 18)     17496       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 126)    0           concatenate_28[0][0]             \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 126)    504         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 126)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 18)     20412       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 144)    0           concatenate_29[0][0]             \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 144)    576         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 144)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 18)     23328       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 162)    0           concatenate_30[0][0]             \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 162)    648         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 162)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 18)     26244       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 180)    0           concatenate_31[0][0]             \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 180)    720         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 180)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 18)     29160       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 198)    0           concatenate_32[0][0]             \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 198)    792         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 198)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 18)     32076       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 216)    0           concatenate_33[0][0]             \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 216)    864         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 216)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 18)     34992       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 234)    0           concatenate_34[0][0]             \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 234)    936         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 234)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 18)     4212        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 18)     0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 18)     72          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 18)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 4, 18)     2916        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 36)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 36)     144         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 36)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 4, 18)     5832        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 54)     0           concatenate_36[0][0]             \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4, 54)     216         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 54)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 4, 18)     8748        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 72)     0           concatenate_37[0][0]             \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 72)     288         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 72)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 4, 4, 18)     11664       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 90)     0           concatenate_38[0][0]             \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 90)     360         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 90)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 4, 4, 18)     14580       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 108)    0           concatenate_39[0][0]             \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 108)    432         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 108)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 4, 4, 18)     17496       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 126)    0           concatenate_40[0][0]             \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 126)    504         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 126)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 18)     20412       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 144)    0           concatenate_41[0][0]             \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 144)    576         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 144)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 18)     23328       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 162)    0           concatenate_42[0][0]             \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 162)    648         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 162)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 18)     26244       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 180)    0           concatenate_43[0][0]             \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 180)    720         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 180)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 18)     29160       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 198)    0           concatenate_44[0][0]             \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 198)    792         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 198)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 18)     32076       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 216)    0           concatenate_45[0][0]             \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 216)    864         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 216)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 18)     34992       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 234)    0           concatenate_46[0][0]             \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 234)    936         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 234)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 234)    0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 1, 1, 10)     9370        average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 1, 1, 10)     0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10)           0           activation_52[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 995,230\n",
      "Trainable params: 981,658\n",
      "Non-trainable params: 13,572\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model(inputs=[input], outputs=[output])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhpOynp71RAq"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CqErxlWeNw5"
   },
   "source": [
    "4. Without use Image Augmentation Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YHYcMaZY1S-v",
    "outputId": "f7c52c68-4f0b-4fc3-ff63-955a7a04ed27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "50000/50000 [==============================] - 134s 3ms/sample - loss: 1.3443 - acc: 0.5108 - val_loss: 1.7591 - val_acc: 0.3901\n",
      "Epoch 2/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.8689 - acc: 0.6896 - val_loss: 1.0018 - val_acc: 0.6554\n",
      "Epoch 3/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.6847 - acc: 0.7581 - val_loss: 0.7081 - val_acc: 0.7513\n",
      "Epoch 4/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.5676 - acc: 0.8010 - val_loss: 1.1526 - val_acc: 0.6628\n",
      "Epoch 5/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.4913 - acc: 0.8289 - val_loss: 0.7590 - val_acc: 0.7545\n",
      "Epoch 6/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.4226 - acc: 0.8523 - val_loss: 0.9314 - val_acc: 0.7074\n",
      "Epoch 7/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.3659 - acc: 0.8716 - val_loss: 1.0074 - val_acc: 0.6984\n",
      "Epoch 8/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.3170 - acc: 0.8898 - val_loss: 0.7834 - val_acc: 0.7677\n",
      "Epoch 9/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.2743 - acc: 0.9029 - val_loss: 0.6990 - val_acc: 0.7790\n",
      "Epoch 10/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.2382 - acc: 0.9162 - val_loss: 0.9570 - val_acc: 0.7351\n",
      "Epoch 11/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.2081 - acc: 0.9265 - val_loss: 0.6206 - val_acc: 0.8150\n",
      "Epoch 12/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.1690 - acc: 0.9396 - val_loss: 1.0392 - val_acc: 0.7457\n",
      "Epoch 13/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.1503 - acc: 0.9470 - val_loss: 0.8672 - val_acc: 0.7866\n",
      "Epoch 14/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.1271 - acc: 0.9546 - val_loss: 0.8370 - val_acc: 0.7919\n",
      "Epoch 15/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.1151 - acc: 0.9591 - val_loss: 0.8448 - val_acc: 0.7972\n",
      "Epoch 16/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0935 - acc: 0.9669 - val_loss: 0.8797 - val_acc: 0.7936\n",
      "Epoch 17/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0960 - acc: 0.9660 - val_loss: 0.7592 - val_acc: 0.8196\n",
      "Epoch 18/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0761 - acc: 0.9728 - val_loss: 0.9563 - val_acc: 0.7972\n",
      "Epoch 19/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0838 - acc: 0.9702 - val_loss: 0.9347 - val_acc: 0.8002\n",
      "Epoch 20/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0660 - acc: 0.9766 - val_loss: 1.0032 - val_acc: 0.7975\n",
      "Epoch 21/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0676 - acc: 0.9762 - val_loss: 0.9245 - val_acc: 0.8000\n",
      "Epoch 22/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0674 - acc: 0.9760 - val_loss: 0.9856 - val_acc: 0.8007\n",
      "Epoch 23/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0640 - acc: 0.9775 - val_loss: 1.0772 - val_acc: 0.7841\n",
      "Epoch 24/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0504 - acc: 0.9824 - val_loss: 0.9070 - val_acc: 0.8209\n",
      "Epoch 25/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0436 - acc: 0.9850 - val_loss: 1.1382 - val_acc: 0.7765\n",
      "Epoch 26/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0586 - acc: 0.9791 - val_loss: 0.8974 - val_acc: 0.8084\n",
      "Epoch 27/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0440 - acc: 0.9850 - val_loss: 0.8772 - val_acc: 0.8171\n",
      "Epoch 28/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0431 - acc: 0.9852 - val_loss: 1.0561 - val_acc: 0.7990\n",
      "Epoch 29/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0467 - acc: 0.9838 - val_loss: 0.9764 - val_acc: 0.8187\n",
      "Epoch 30/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0474 - acc: 0.9835 - val_loss: 1.0974 - val_acc: 0.7971\n",
      "Epoch 31/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0367 - acc: 0.9870 - val_loss: 0.9546 - val_acc: 0.8085\n",
      "Epoch 32/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0339 - acc: 0.9879 - val_loss: 1.0321 - val_acc: 0.8132\n",
      "Epoch 33/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0390 - acc: 0.9864 - val_loss: 0.9516 - val_acc: 0.8219\n",
      "Epoch 34/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0338 - acc: 0.9878 - val_loss: 0.9801 - val_acc: 0.8212\n",
      "Epoch 35/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0335 - acc: 0.9885 - val_loss: 1.0146 - val_acc: 0.8207\n",
      "Epoch 36/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0441 - acc: 0.9842 - val_loss: 1.0133 - val_acc: 0.8154\n",
      "Epoch 37/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0282 - acc: 0.9905 - val_loss: 1.2679 - val_acc: 0.7763\n",
      "Epoch 38/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0266 - acc: 0.9908 - val_loss: 0.9807 - val_acc: 0.8241\n",
      "Epoch 39/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0298 - acc: 0.9897 - val_loss: 1.0016 - val_acc: 0.8216\n",
      "Epoch 40/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0310 - acc: 0.9896 - val_loss: 1.2716 - val_acc: 0.7904\n",
      "Epoch 41/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0380 - acc: 0.9863 - val_loss: 1.2115 - val_acc: 0.7935\n",
      "Epoch 42/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0285 - acc: 0.9899 - val_loss: 1.0746 - val_acc: 0.8132\n",
      "Epoch 43/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0198 - acc: 0.9934 - val_loss: 0.9930 - val_acc: 0.8297\n",
      "Epoch 44/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0252 - acc: 0.9915 - val_loss: 1.0507 - val_acc: 0.8265\n",
      "Epoch 45/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0358 - acc: 0.9880 - val_loss: 1.1530 - val_acc: 0.8064\n",
      "Epoch 46/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0221 - acc: 0.9925 - val_loss: 0.9613 - val_acc: 0.8270\n",
      "Epoch 47/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0230 - acc: 0.9918 - val_loss: 1.0209 - val_acc: 0.8217\n",
      "Epoch 48/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0311 - acc: 0.9894 - val_loss: 1.0780 - val_acc: 0.8212\n",
      "Epoch 49/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0182 - acc: 0.9937 - val_loss: 0.9739 - val_acc: 0.8303\n",
      "Epoch 50/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0235 - acc: 0.9918 - val_loss: 1.0470 - val_acc: 0.8298\n",
      "Epoch 51/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0275 - acc: 0.9906 - val_loss: 1.1015 - val_acc: 0.8055\n",
      "Epoch 52/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0220 - acc: 0.9922 - val_loss: 1.1770 - val_acc: 0.8105\n",
      "Epoch 53/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0244 - acc: 0.9914 - val_loss: 1.1219 - val_acc: 0.8148\n",
      "Epoch 54/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0195 - acc: 0.9931 - val_loss: 0.9504 - val_acc: 0.8317\n",
      "Epoch 55/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0186 - acc: 0.9934 - val_loss: 1.1449 - val_acc: 0.8101\n",
      "Epoch 56/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0225 - acc: 0.9922 - val_loss: 1.1274 - val_acc: 0.8251\n",
      "Epoch 57/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0221 - acc: 0.9923 - val_loss: 1.0067 - val_acc: 0.8282\n",
      "Epoch 58/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0240 - acc: 0.9916 - val_loss: 0.9781 - val_acc: 0.8329\n",
      "Epoch 59/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0231 - acc: 0.9921 - val_loss: 0.9233 - val_acc: 0.8407\n",
      "Epoch 60/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0080 - acc: 0.9975 - val_loss: 0.9485 - val_acc: 0.8420\n",
      "Epoch 61/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0059 - acc: 0.9985 - val_loss: 1.0705 - val_acc: 0.8358\n",
      "Epoch 62/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0375 - acc: 0.9873 - val_loss: 1.0968 - val_acc: 0.8207\n",
      "Epoch 63/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0222 - acc: 0.9925 - val_loss: 1.0349 - val_acc: 0.8293\n",
      "Epoch 64/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0105 - acc: 0.9967 - val_loss: 1.0016 - val_acc: 0.8368\n",
      "Epoch 65/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0224 - acc: 0.9922 - val_loss: 1.3154 - val_acc: 0.8017\n",
      "Epoch 66/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0184 - acc: 0.9940 - val_loss: 0.9403 - val_acc: 0.8362\n",
      "Epoch 67/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0065 - acc: 0.9978 - val_loss: 0.9529 - val_acc: 0.8444\n",
      "Epoch 68/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0097 - acc: 0.9968 - val_loss: 1.1523 - val_acc: 0.8139\n",
      "Epoch 69/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0380 - acc: 0.9871 - val_loss: 0.9573 - val_acc: 0.8355\n",
      "Epoch 70/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0164 - acc: 0.9943 - val_loss: 0.9756 - val_acc: 0.8389\n",
      "Epoch 71/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0047 - acc: 0.9986 - val_loss: 0.8990 - val_acc: 0.8505\n",
      "Epoch 72/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0026 - acc: 0.9994 - val_loss: 1.0073 - val_acc: 0.8402\n",
      "Epoch 73/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0347 - acc: 0.9881 - val_loss: 1.2522 - val_acc: 0.8061\n",
      "Epoch 74/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0214 - acc: 0.9924 - val_loss: 0.9833 - val_acc: 0.8272\n",
      "Epoch 75/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0100 - acc: 0.9966 - val_loss: 0.9767 - val_acc: 0.8374\n",
      "Epoch 76/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0081 - acc: 0.9972 - val_loss: 1.0905 - val_acc: 0.8318\n",
      "Epoch 77/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0163 - acc: 0.9944 - val_loss: 0.9995 - val_acc: 0.8351\n",
      "Epoch 78/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0209 - acc: 0.9925 - val_loss: 0.9669 - val_acc: 0.8431\n",
      "Epoch 79/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0123 - acc: 0.9960 - val_loss: 1.0251 - val_acc: 0.8295\n",
      "Epoch 80/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0116 - acc: 0.9962 - val_loss: 1.0408 - val_acc: 0.8378\n",
      "Epoch 81/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0210 - acc: 0.9930 - val_loss: 1.0576 - val_acc: 0.8344\n",
      "Epoch 82/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0144 - acc: 0.9950 - val_loss: 1.0200 - val_acc: 0.8338\n",
      "Epoch 83/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0118 - acc: 0.9962 - val_loss: 1.0747 - val_acc: 0.8344\n",
      "Epoch 84/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0125 - acc: 0.9957 - val_loss: 1.1207 - val_acc: 0.8274\n",
      "Epoch 85/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0124 - acc: 0.9958 - val_loss: 0.9849 - val_acc: 0.8421\n",
      "Epoch 86/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0161 - acc: 0.9948 - val_loss: 1.1589 - val_acc: 0.8315\n",
      "Epoch 87/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0144 - acc: 0.9950 - val_loss: 1.0566 - val_acc: 0.8328\n",
      "Epoch 88/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0042 - acc: 0.9986 - val_loss: 1.0330 - val_acc: 0.8420\n",
      "Epoch 89/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0035 - acc: 0.9990 - val_loss: 1.0778 - val_acc: 0.8383\n",
      "Epoch 90/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0331 - acc: 0.9887 - val_loss: 1.1734 - val_acc: 0.8148\n",
      "Epoch 91/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0157 - acc: 0.9943 - val_loss: 1.0388 - val_acc: 0.8297\n",
      "Epoch 92/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0046 - acc: 0.9984 - val_loss: 0.9206 - val_acc: 0.8540\n",
      "Epoch 93/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0023 - acc: 0.9994 - val_loss: 0.9516 - val_acc: 0.8476\n",
      "Epoch 94/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0016 - acc: 0.9996 - val_loss: 0.9895 - val_acc: 0.8480\n",
      "Epoch 95/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0317 - acc: 0.9892 - val_loss: 1.1777 - val_acc: 0.8218\n",
      "Epoch 96/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0147 - acc: 0.9952 - val_loss: 0.9128 - val_acc: 0.8473\n",
      "Epoch 97/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0032 - acc: 0.9991 - val_loss: 0.9211 - val_acc: 0.8512\n",
      "Epoch 98/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0034 - acc: 0.9990 - val_loss: 1.1220 - val_acc: 0.8262\n",
      "Epoch 99/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0204 - acc: 0.9932 - val_loss: 1.1817 - val_acc: 0.8169\n",
      "Epoch 100/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0229 - acc: 0.9922 - val_loss: 0.9790 - val_acc: 0.8399\n",
      "Epoch 101/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0093 - acc: 0.9968 - val_loss: 0.9600 - val_acc: 0.8449\n",
      "Epoch 102/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0039 - acc: 0.9988 - val_loss: 0.9762 - val_acc: 0.8465\n",
      "Epoch 103/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0029 - acc: 0.9991 - val_loss: 1.0058 - val_acc: 0.8447\n",
      "Epoch 104/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0173 - acc: 0.9944 - val_loss: 1.1525 - val_acc: 0.8236\n",
      "Epoch 105/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0158 - acc: 0.9947 - val_loss: 1.1299 - val_acc: 0.8232\n",
      "Epoch 106/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0097 - acc: 0.9967 - val_loss: 1.1331 - val_acc: 0.8363\n",
      "Epoch 107/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0082 - acc: 0.9973 - val_loss: 1.0398 - val_acc: 0.8406\n",
      "Epoch 108/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0125 - acc: 0.9956 - val_loss: 1.1235 - val_acc: 0.8261\n",
      "Epoch 109/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0157 - acc: 0.9949 - val_loss: 1.1041 - val_acc: 0.8291\n",
      "Epoch 110/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0029 - acc: 0.9991 - val_loss: 0.9362 - val_acc: 0.8543\n",
      "Epoch 111/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0036 - acc: 0.9989 - val_loss: 1.0206 - val_acc: 0.8425\n",
      "Epoch 112/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0191 - acc: 0.9936 - val_loss: 1.1841 - val_acc: 0.8292\n",
      "Epoch 113/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0148 - acc: 0.9951 - val_loss: 1.0483 - val_acc: 0.8394\n",
      "Epoch 114/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0085 - acc: 0.9972 - val_loss: 1.0114 - val_acc: 0.8432\n",
      "Epoch 115/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0042 - acc: 0.9986 - val_loss: 0.9619 - val_acc: 0.8529\n",
      "Epoch 116/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 8.9669e-04 - acc: 0.9999 - val_loss: 0.9091 - val_acc: 0.8596\n",
      "Epoch 117/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 3.0840e-04 - acc: 1.0000 - val_loss: 0.9442 - val_acc: 0.8570\n",
      "Epoch 118/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 1.9222e-04 - acc: 1.0000 - val_loss: 0.9284 - val_acc: 0.8572\n",
      "Epoch 119/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 2.0548e-04 - acc: 1.0000 - val_loss: 0.9723 - val_acc: 0.8513\n",
      "Epoch 120/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0502 - acc: 0.9854 - val_loss: 1.1841 - val_acc: 0.8177\n",
      "Epoch 121/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0111 - acc: 0.9965 - val_loss: 0.9051 - val_acc: 0.8509\n",
      "Epoch 122/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0035 - acc: 0.9992 - val_loss: 0.8652 - val_acc: 0.8551\n",
      "Epoch 123/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0011 - acc: 0.9998 - val_loss: 0.8946 - val_acc: 0.8559\n",
      "Epoch 124/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 3.3141e-04 - acc: 1.0000 - val_loss: 0.8955 - val_acc: 0.8559\n",
      "Epoch 125/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 3.4934e-04 - acc: 1.0000 - val_loss: 0.8984 - val_acc: 0.8590\n",
      "Epoch 126/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 2.0631e-04 - acc: 1.0000 - val_loss: 0.9179 - val_acc: 0.8571\n",
      "Epoch 127/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 1.4972e-04 - acc: 1.0000 - val_loss: 0.9160 - val_acc: 0.8590\n",
      "Epoch 128/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 7.2511e-05 - acc: 1.0000 - val_loss: 0.9216 - val_acc: 0.8591\n",
      "Epoch 129/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0060 - acc: 0.9984 - val_loss: 1.8173 - val_acc: 0.7557\n",
      "Epoch 130/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0664 - acc: 0.9784 - val_loss: 0.9688 - val_acc: 0.8289\n",
      "Epoch 131/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0043 - acc: 0.9989 - val_loss: 0.8175 - val_acc: 0.8540\n",
      "Epoch 132/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0011 - acc: 0.9998 - val_loss: 0.8294 - val_acc: 0.8596\n",
      "Epoch 133/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 4.4160e-04 - acc: 1.0000 - val_loss: 0.8324 - val_acc: 0.8611\n",
      "Epoch 134/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 2.0742e-04 - acc: 1.0000 - val_loss: 0.8410 - val_acc: 0.8625\n",
      "Epoch 135/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 9.0745e-04 - acc: 0.9999 - val_loss: 0.8997 - val_acc: 0.8569\n",
      "Epoch 136/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0343 - acc: 0.9887 - val_loss: 0.9916 - val_acc: 0.8271\n",
      "Epoch 137/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0110 - acc: 0.9961 - val_loss: 0.9545 - val_acc: 0.8420\n",
      "Epoch 138/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0043 - acc: 0.9987 - val_loss: 0.9190 - val_acc: 0.8482\n",
      "Epoch 139/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.9074 - val_acc: 0.8524\n",
      "Epoch 140/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 3.9840e-04 - acc: 1.0000 - val_loss: 0.9010 - val_acc: 0.8547\n",
      "Epoch 141/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 2.6018e-04 - acc: 1.0000 - val_loss: 0.8995 - val_acc: 0.8551\n",
      "Epoch 142/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 1.3516e-04 - acc: 1.0000 - val_loss: 0.9033 - val_acc: 0.8548\n",
      "Epoch 143/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 7.2716e-05 - acc: 1.0000 - val_loss: 0.9054 - val_acc: 0.8559\n",
      "Epoch 144/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 5.4286e-05 - acc: 1.0000 - val_loss: 0.9119 - val_acc: 0.8580\n",
      "Epoch 145/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 4.3497e-05 - acc: 1.0000 - val_loss: 0.9145 - val_acc: 0.8586\n",
      "Epoch 146/300\n",
      "50000/50000 [==============================] - 114s 2ms/sample - loss: 3.5640e-05 - acc: 1.0000 - val_loss: 0.9263 - val_acc: 0.8567\n",
      "Epoch 147/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 3.2485e-05 - acc: 1.0000 - val_loss: 0.9253 - val_acc: 0.8555\n",
      "Epoch 148/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 3.7064e-05 - acc: 1.0000 - val_loss: 0.9363 - val_acc: 0.8567\n",
      "Epoch 149/300\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 3.0460e-05 - acc: 1.0000 - val_loss: 0.9485 - val_acc: 0.8570\n",
      "Epoch 150/300\n",
      "25472/50000 [==============>...............] - ETA: 53s - loss: 2.1300e-05 - acc: 1.0000Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "model_2.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=300,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V211MjyC3WWt"
   },
   "source": [
    "4. Using Image Augmentation Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SKXRMOycQQp7",
    "outputId": "3bbf19ce-d9ee-4348-a7b1-d1b5b49fe2c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Data augementation\n",
    "image_gen = ImageDataGenerator(rotation_range=20,width_shift_range=0.125,height_shift_range=0.125,horizontal_flip=True,fill_mode='nearest',zoom_range=0.10)\n",
    "\n",
    "image_gen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3bkdxa8y5G7C",
    "outputId": "0f8de4cc-bcd6-43df-baea-9783a0afa764"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2U5FJ2eaPxPt",
    "outputId": "ef54d537-bc4e-46d9-d5bb-40b311523858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 36)   972         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 36)   144         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 36)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 18)   5832        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 54)   0           conv2d[0][0]                     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 54)   216         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 54)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 18)   8748        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 72)   0           concatenate[0][0]                \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 72)   288         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 72)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 18)   11664       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 90)   0           concatenate_1[0][0]              \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 90)   360         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 90)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 18)   14580       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 108)  0           concatenate_2[0][0]              \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 108)  432         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 108)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 18)   17496       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 126)  0           concatenate_3[0][0]              \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 126)  504         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 126)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 18)   20412       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 144)  0           concatenate_4[0][0]              \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 144)  576         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 144)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 18)   23328       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 162)  0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 162)  648         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 162)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 18)   26244       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 180)  0           concatenate_6[0][0]              \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 180)  720         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 180)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 18)   29160       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 198)  0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 198)  792         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 198)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 18)   32076       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 216)  0           concatenate_8[0][0]              \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 216)  864         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 216)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 18)   34992       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 234)  0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 234)  936         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 234)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 18)   37908       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 252)  0           concatenate_10[0][0]             \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 252)  1008        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 252)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 18)   4536        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 18)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 18)   72          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 18)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 18)   2916        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 36)   0           average_pooling2d[0][0]          \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 36)   144         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 36)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 18)   5832        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 54)   0           concatenate_12[0][0]             \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 54)   216         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 54)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 18)   8748        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 72)   0           concatenate_13[0][0]             \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 72)   288         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 72)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 18)   11664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 90)   0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 90)   360         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 90)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 18)   14580       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 108)  0           concatenate_15[0][0]             \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 108)  432         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 108)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 18)   17496       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 126)  0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 126)  504         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 126)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 18)   20412       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 144)  0           concatenate_17[0][0]             \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 144)  576         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 144)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 18)   23328       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 162)  0           concatenate_18[0][0]             \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 162)  648         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 162)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 18)   26244       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 180)  0           concatenate_19[0][0]             \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 180)  720         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 180)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 18)   29160       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 198)  0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 198)  792         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 198)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 18)   32076       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 216)  0           concatenate_21[0][0]             \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 216)  864         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 216)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 18)   34992       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 234)  0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 234)  936         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 234)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 18)   4212        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 18)     0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 18)     72          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 18)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 18)     2916        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 36)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 36)     144         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 36)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 18)     5832        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 54)     0           concatenate_24[0][0]             \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 54)     216         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 54)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 18)     8748        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 72)     0           concatenate_25[0][0]             \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 72)     288         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 72)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 18)     11664       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 90)     0           concatenate_26[0][0]             \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 90)     360         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 90)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 18)     14580       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 108)    0           concatenate_27[0][0]             \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 108)    432         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 108)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 18)     17496       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 126)    0           concatenate_28[0][0]             \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 126)    504         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 126)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 18)     20412       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 144)    0           concatenate_29[0][0]             \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 144)    576         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 144)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 18)     23328       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 162)    0           concatenate_30[0][0]             \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 162)    648         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 162)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 18)     26244       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 180)    0           concatenate_31[0][0]             \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 180)    720         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 180)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 18)     29160       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 198)    0           concatenate_32[0][0]             \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 198)    792         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 198)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 18)     32076       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 216)    0           concatenate_33[0][0]             \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 216)    864         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 216)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 18)     34992       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 234)    0           concatenate_34[0][0]             \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 234)    936         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 234)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 18)     4212        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 18)     0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 18)     72          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 18)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 4, 18)     2916        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 36)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 36)     144         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 36)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 4, 18)     5832        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 54)     0           concatenate_36[0][0]             \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4, 54)     216         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 54)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 4, 18)     8748        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 72)     0           concatenate_37[0][0]             \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 72)     288         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 72)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 4, 4, 18)     11664       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 90)     0           concatenate_38[0][0]             \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 90)     360         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 90)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 4, 4, 18)     14580       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 108)    0           concatenate_39[0][0]             \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 108)    432         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 108)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 4, 4, 18)     17496       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 126)    0           concatenate_40[0][0]             \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 126)    504         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 126)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 18)     20412       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 144)    0           concatenate_41[0][0]             \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 144)    576         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 144)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 18)     23328       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 162)    0           concatenate_42[0][0]             \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 162)    648         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 162)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 18)     26244       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 180)    0           concatenate_43[0][0]             \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 180)    720         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 180)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 18)     29160       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 198)    0           concatenate_44[0][0]             \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 198)    792         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 198)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 18)     32076       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 216)    0           concatenate_45[0][0]             \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 216)    864         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 216)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 18)     34992       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 234)    0           concatenate_46[0][0]             \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 234)    936         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 234)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 234)    0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 1, 1, 10)     9370        average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 1, 1, 10)     0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10)           0           activation_52[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 995,230\n",
      "Trainable params: 981,658\n",
      "Non-trainable params: 13,572\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# determine Loss function and Optimizer\n",
    "\n",
    "model_3 = Model(inputs=[input], outputs=[output])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RXGK-57U7_EP",
    "outputId": "656df65b-1d67-4a50-9937-4f73c6435d97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "390/390 [============================>.] - ETA: 0s - loss: 1.5481 - acc: 0.4338Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 5s 509us/sample - loss: 1.7327 - acc: 0.4521\n",
      "391/390 [==============================] - 90s 229ms/step - loss: 1.5474 - acc: 0.4341 - val_loss: 1.6082 - val_acc: 0.4521\n",
      "Epoch 2/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 1.1386 - acc: 0.5915Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 1.7233 - acc: 0.4773\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 1.1380 - acc: 0.5917 - val_loss: 1.8910 - val_acc: 0.4773\n",
      "Epoch 3/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.9522 - acc: 0.6614Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 1.2473 - acc: 0.5218\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.9521 - acc: 0.6614 - val_loss: 1.5820 - val_acc: 0.5218\n",
      "Epoch 4/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.8329 - acc: 0.7059Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 0.9265 - acc: 0.6709\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.8325 - acc: 0.7060 - val_loss: 1.0040 - val_acc: 0.6709\n",
      "Epoch 5/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.7502 - acc: 0.7357Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 344us/sample - loss: 0.8072 - acc: 0.7050\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.7499 - acc: 0.7358 - val_loss: 0.8748 - val_acc: 0.7050\n",
      "Epoch 6/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.6915 - acc: 0.7607Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 344us/sample - loss: 0.6871 - acc: 0.7196\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.6912 - acc: 0.7608 - val_loss: 0.8572 - val_acc: 0.7196\n",
      "Epoch 7/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.6498 - acc: 0.7745Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 341us/sample - loss: 0.7215 - acc: 0.7353\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.6497 - acc: 0.7745 - val_loss: 0.8115 - val_acc: 0.7353\n",
      "Epoch 8/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.6065 - acc: 0.7890Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.7783 - acc: 0.6901\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.6063 - acc: 0.7890 - val_loss: 1.0597 - val_acc: 0.6901\n",
      "Epoch 9/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.5721 - acc: 0.8015Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.6258 - acc: 0.7591\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.5722 - acc: 0.8014 - val_loss: 0.7261 - val_acc: 0.7591\n",
      "Epoch 10/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.5369 - acc: 0.8130Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 340us/sample - loss: 0.8036 - acc: 0.7417\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.5368 - acc: 0.8130 - val_loss: 0.8459 - val_acc: 0.7417\n",
      "Epoch 11/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.5085 - acc: 0.8233Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 1.0177 - acc: 0.6947\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.5081 - acc: 0.8235 - val_loss: 0.9929 - val_acc: 0.6947\n",
      "Epoch 12/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.4957 - acc: 0.8272Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.5870 - acc: 0.8132\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.4954 - acc: 0.8273 - val_loss: 0.5635 - val_acc: 0.8132\n",
      "Epoch 13/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.4705 - acc: 0.8375Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.5254 - acc: 0.8088\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.4704 - acc: 0.8376 - val_loss: 0.5729 - val_acc: 0.8088\n",
      "Epoch 14/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.4514 - acc: 0.8425Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 0.4249 - acc: 0.8329\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.4513 - acc: 0.8425 - val_loss: 0.5048 - val_acc: 0.8329\n",
      "Epoch 15/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.4345 - acc: 0.8498Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 0.4717 - acc: 0.8317\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.4345 - acc: 0.8498 - val_loss: 0.4998 - val_acc: 0.8317\n",
      "Epoch 16/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.4225 - acc: 0.8538Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 338us/sample - loss: 0.9650 - acc: 0.7500\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.4223 - acc: 0.8539 - val_loss: 0.8666 - val_acc: 0.7500\n",
      "Epoch 17/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.4108 - acc: 0.8580Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.5146 - acc: 0.8142\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.4109 - acc: 0.8579 - val_loss: 0.5921 - val_acc: 0.8142\n",
      "Epoch 18/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.3909 - acc: 0.8637Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.6491 - acc: 0.8210\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.3911 - acc: 0.8636 - val_loss: 0.5658 - val_acc: 0.8210\n",
      "Epoch 19/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.3798 - acc: 0.8683Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.6690 - acc: 0.8157\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.3800 - acc: 0.8683 - val_loss: 0.5763 - val_acc: 0.8157\n",
      "Epoch 20/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.3700 - acc: 0.8726Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.7150 - acc: 0.7832\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.3704 - acc: 0.8725 - val_loss: 0.7143 - val_acc: 0.7832\n",
      "Epoch 21/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.3567 - acc: 0.8769Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 0.5130 - acc: 0.8306\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.3567 - acc: 0.8769 - val_loss: 0.5496 - val_acc: 0.8306\n",
      "Epoch 22/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.3473 - acc: 0.8807Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.5707 - acc: 0.8435\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.3474 - acc: 0.8807 - val_loss: 0.4788 - val_acc: 0.8435\n",
      "Epoch 23/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.3330 - acc: 0.8851Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.4656 - acc: 0.8315\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.3329 - acc: 0.8851 - val_loss: 0.5568 - val_acc: 0.8315\n",
      "Epoch 24/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.3278 - acc: 0.8858Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.5528 - acc: 0.8466\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.3276 - acc: 0.8859 - val_loss: 0.4982 - val_acc: 0.8466\n",
      "Epoch 25/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.3196 - acc: 0.8882Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.6492 - acc: 0.8354\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.3200 - acc: 0.8880 - val_loss: 0.5288 - val_acc: 0.8354\n",
      "Epoch 26/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.3148 - acc: 0.8905Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.5578 - acc: 0.8315\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.3151 - acc: 0.8904 - val_loss: 0.5329 - val_acc: 0.8315\n",
      "Epoch 27/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.8946Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 342us/sample - loss: 0.8301 - acc: 0.8098\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.3042 - acc: 0.8945 - val_loss: 0.6771 - val_acc: 0.8098\n",
      "Epoch 28/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2988 - acc: 0.8960Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 341us/sample - loss: 0.7485 - acc: 0.8066\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.2987 - acc: 0.8960 - val_loss: 0.6179 - val_acc: 0.8066\n",
      "Epoch 29/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2889 - acc: 0.8996Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 347us/sample - loss: 0.4320 - acc: 0.8778\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.2888 - acc: 0.8995 - val_loss: 0.3772 - val_acc: 0.8778\n",
      "Epoch 30/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2821 - acc: 0.9004Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3719 - acc: 0.8606\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.2821 - acc: 0.9004 - val_loss: 0.4475 - val_acc: 0.8606\n",
      "Epoch 31/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2757 - acc: 0.9042Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 0.4802 - acc: 0.8757\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.2755 - acc: 0.9043 - val_loss: 0.3875 - val_acc: 0.8757\n",
      "Epoch 32/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9060Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.3427 - acc: 0.8823\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.2709 - acc: 0.9060 - val_loss: 0.3598 - val_acc: 0.8823\n",
      "Epoch 33/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2638 - acc: 0.9091Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3545 - acc: 0.8537\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.2638 - acc: 0.9091 - val_loss: 0.4642 - val_acc: 0.8537\n",
      "Epoch 34/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2549 - acc: 0.9099Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.6909 - acc: 0.8425\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.2548 - acc: 0.9099 - val_loss: 0.5350 - val_acc: 0.8425\n",
      "Epoch 35/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2540 - acc: 0.9117Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.6957 - acc: 0.8284\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.2540 - acc: 0.9117 - val_loss: 0.6168 - val_acc: 0.8284\n",
      "Epoch 36/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2513 - acc: 0.9121Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.3315 - acc: 0.8371\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.2515 - acc: 0.9120 - val_loss: 0.5412 - val_acc: 0.8371\n",
      "Epoch 37/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2435 - acc: 0.9153Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.7685 - acc: 0.8094\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.2435 - acc: 0.9153 - val_loss: 0.7127 - val_acc: 0.8094\n",
      "Epoch 38/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9187Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.6370 - acc: 0.8591\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.2348 - acc: 0.9186 - val_loss: 0.4915 - val_acc: 0.8591\n",
      "Epoch 39/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2347 - acc: 0.9183Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.3515 - acc: 0.8781\n",
      "391/390 [==============================] - 69s 175ms/step - loss: 0.2346 - acc: 0.9183 - val_loss: 0.3853 - val_acc: 0.8781\n",
      "Epoch 40/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2277 - acc: 0.9202Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 338us/sample - loss: 0.3638 - acc: 0.8855\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.2279 - acc: 0.9202 - val_loss: 0.3650 - val_acc: 0.8855\n",
      "Epoch 41/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2259 - acc: 0.9212Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3647 - acc: 0.8739\n",
      "391/390 [==============================] - 69s 175ms/step - loss: 0.2261 - acc: 0.9211 - val_loss: 0.4158 - val_acc: 0.8739\n",
      "Epoch 42/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2182 - acc: 0.9234Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.3555 - acc: 0.8724\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.2180 - acc: 0.9235 - val_loss: 0.4094 - val_acc: 0.8724\n",
      "Epoch 43/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2151 - acc: 0.9236Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.4644 - acc: 0.8797\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.2154 - acc: 0.9235 - val_loss: 0.3958 - val_acc: 0.8797\n",
      "Epoch 44/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2114 - acc: 0.9263Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 343us/sample - loss: 0.4282 - acc: 0.8603\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.2113 - acc: 0.9264 - val_loss: 0.4765 - val_acc: 0.8603\n",
      "Epoch 45/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2082 - acc: 0.9276Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 338us/sample - loss: 0.6363 - acc: 0.8301\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.2082 - acc: 0.9275 - val_loss: 0.5865 - val_acc: 0.8301\n",
      "Epoch 46/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2059 - acc: 0.9274Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.3934 - acc: 0.8516\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.2058 - acc: 0.9275 - val_loss: 0.5119 - val_acc: 0.8516\n",
      "Epoch 47/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9280Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 340us/sample - loss: 0.4406 - acc: 0.8651\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.2038 - acc: 0.9279 - val_loss: 0.4614 - val_acc: 0.8651\n",
      "Epoch 48/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9313Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 340us/sample - loss: 0.3795 - acc: 0.8717\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.1955 - acc: 0.9313 - val_loss: 0.4190 - val_acc: 0.8717\n",
      "Epoch 49/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1877 - acc: 0.9347Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.3601 - acc: 0.8640\n",
      "391/390 [==============================] - 69s 175ms/step - loss: 0.1878 - acc: 0.9347 - val_loss: 0.4544 - val_acc: 0.8640\n",
      "Epoch 50/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9330Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.6376 - acc: 0.8649\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.1918 - acc: 0.9330 - val_loss: 0.4450 - val_acc: 0.8649\n",
      "Epoch 51/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9341Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 341us/sample - loss: 0.2816 - acc: 0.8772\n",
      "391/390 [==============================] - 69s 175ms/step - loss: 0.1869 - acc: 0.9340 - val_loss: 0.4033 - val_acc: 0.8772\n",
      "Epoch 52/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1831 - acc: 0.9346Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.3694 - acc: 0.8690\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.1830 - acc: 0.9347 - val_loss: 0.4499 - val_acc: 0.8690\n",
      "Epoch 53/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9339Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.4245 - acc: 0.8923\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.1844 - acc: 0.9339 - val_loss: 0.3606 - val_acc: 0.8923\n",
      "Epoch 54/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9378Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 338us/sample - loss: 0.3912 - acc: 0.8773\n",
      "391/390 [==============================] - 69s 175ms/step - loss: 0.1770 - acc: 0.9378 - val_loss: 0.4068 - val_acc: 0.8773\n",
      "Epoch 55/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9387Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.2148 - acc: 0.8832\n",
      "391/390 [==============================] - 69s 175ms/step - loss: 0.1752 - acc: 0.9386 - val_loss: 0.3894 - val_acc: 0.8832\n",
      "Epoch 56/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9381Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 342us/sample - loss: 0.3085 - acc: 0.8742\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.1748 - acc: 0.9381 - val_loss: 0.4441 - val_acc: 0.8742\n",
      "Epoch 57/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9406Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 338us/sample - loss: 0.3132 - acc: 0.8868\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.1681 - acc: 0.9406 - val_loss: 0.3905 - val_acc: 0.8868\n",
      "Epoch 58/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1670 - acc: 0.9415Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 343us/sample - loss: 0.3557 - acc: 0.8667\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.1670 - acc: 0.9414 - val_loss: 0.4810 - val_acc: 0.8667\n",
      "Epoch 59/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9415Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 0.3181 - acc: 0.8894\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.1677 - acc: 0.9415 - val_loss: 0.3741 - val_acc: 0.8894\n",
      "Epoch 60/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1637 - acc: 0.9418Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3213 - acc: 0.8811\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.1635 - acc: 0.9419 - val_loss: 0.4141 - val_acc: 0.8811\n",
      "Epoch 61/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1593 - acc: 0.9436Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 341us/sample - loss: 0.3554 - acc: 0.8815\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.1592 - acc: 0.9436 - val_loss: 0.4172 - val_acc: 0.8815\n",
      "Epoch 62/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9440Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 0.5743 - acc: 0.8778\n",
      "391/390 [==============================] - 69s 175ms/step - loss: 0.1580 - acc: 0.9438 - val_loss: 0.4537 - val_acc: 0.8778\n",
      "Epoch 63/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1531 - acc: 0.9458Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 338us/sample - loss: 0.3914 - acc: 0.8831\n",
      "391/390 [==============================] - 69s 175ms/step - loss: 0.1529 - acc: 0.9459 - val_loss: 0.3959 - val_acc: 0.8831\n",
      "Epoch 64/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9457Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.4871 - acc: 0.8714\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.1558 - acc: 0.9457 - val_loss: 0.4499 - val_acc: 0.8714\n",
      "Epoch 65/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9458Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4058 - acc: 0.8986\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1528 - acc: 0.9458 - val_loss: 0.3362 - val_acc: 0.8986\n",
      "Epoch 66/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9474Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.2216 - acc: 0.8965\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.1486 - acc: 0.9473 - val_loss: 0.3574 - val_acc: 0.8965\n",
      "Epoch 67/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9495Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.2477 - acc: 0.9056\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1458 - acc: 0.9495 - val_loss: 0.3252 - val_acc: 0.9056\n",
      "Epoch 68/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9490Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.4238 - acc: 0.8676\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1424 - acc: 0.9490 - val_loss: 0.5040 - val_acc: 0.8676\n",
      "Epoch 69/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9497Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.5749 - acc: 0.8885\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1437 - acc: 0.9497 - val_loss: 0.3925 - val_acc: 0.8885\n",
      "Epoch 70/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9509Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.5235 - acc: 0.8786\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1378 - acc: 0.9509 - val_loss: 0.4320 - val_acc: 0.8786\n",
      "Epoch 71/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9496Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2309 - acc: 0.8856\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1437 - acc: 0.9496 - val_loss: 0.4060 - val_acc: 0.8856\n",
      "Epoch 72/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9531Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2554 - acc: 0.8928\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1337 - acc: 0.9532 - val_loss: 0.3851 - val_acc: 0.8928\n",
      "Epoch 73/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9515Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3755 - acc: 0.8917\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1358 - acc: 0.9515 - val_loss: 0.3875 - val_acc: 0.8917\n",
      "Epoch 74/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9526Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3174 - acc: 0.8872\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1328 - acc: 0.9525 - val_loss: 0.3960 - val_acc: 0.8872\n",
      "Epoch 75/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9544Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2406 - acc: 0.8848\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1286 - acc: 0.9544 - val_loss: 0.4021 - val_acc: 0.8848\n",
      "Epoch 76/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9534Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.3164 - acc: 0.8652\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1314 - acc: 0.9533 - val_loss: 0.5008 - val_acc: 0.8652\n",
      "Epoch 77/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9551Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.3567 - acc: 0.8837\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1267 - acc: 0.9550 - val_loss: 0.4267 - val_acc: 0.8837\n",
      "Epoch 78/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9566Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2548 - acc: 0.8965\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1231 - acc: 0.9566 - val_loss: 0.3682 - val_acc: 0.8965\n",
      "Epoch 79/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9568Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.4017 - acc: 0.8935\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1239 - acc: 0.9568 - val_loss: 0.4058 - val_acc: 0.8935\n",
      "Epoch 80/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9564Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2939 - acc: 0.8877\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1239 - acc: 0.9564 - val_loss: 0.3991 - val_acc: 0.8877\n",
      "Epoch 81/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9576Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.4480 - acc: 0.8811\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1209 - acc: 0.9576 - val_loss: 0.4491 - val_acc: 0.8811\n",
      "Epoch 82/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9580Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.4173 - acc: 0.8912\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1178 - acc: 0.9580 - val_loss: 0.4105 - val_acc: 0.8912\n",
      "Epoch 83/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9582Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2585 - acc: 0.8923\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1190 - acc: 0.9582 - val_loss: 0.3995 - val_acc: 0.8923\n",
      "Epoch 84/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9587Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.2096 - acc: 0.8954\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1161 - acc: 0.9586 - val_loss: 0.3878 - val_acc: 0.8954\n",
      "Epoch 85/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9605Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 338us/sample - loss: 0.3145 - acc: 0.8950\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1132 - acc: 0.9605 - val_loss: 0.3756 - val_acc: 0.8950\n",
      "Epoch 86/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9592Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.2854 - acc: 0.8945\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1177 - acc: 0.9591 - val_loss: 0.3840 - val_acc: 0.8945\n",
      "Epoch 87/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9584Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 340us/sample - loss: 0.6287 - acc: 0.8656\n",
      "391/390 [==============================] - 69s 175ms/step - loss: 0.1156 - acc: 0.9584 - val_loss: 0.5710 - val_acc: 0.8656\n",
      "Epoch 88/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9594Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.1931 - acc: 0.8991\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1122 - acc: 0.9594 - val_loss: 0.3633 - val_acc: 0.8991\n",
      "Epoch 89/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9597Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 0.2540 - acc: 0.8925\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.1120 - acc: 0.9597 - val_loss: 0.3907 - val_acc: 0.8925\n",
      "Epoch 90/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9611Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.4606 - acc: 0.8907\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1112 - acc: 0.9612 - val_loss: 0.4222 - val_acc: 0.8907\n",
      "Epoch 91/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9608Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3028 - acc: 0.9049\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1109 - acc: 0.9608 - val_loss: 0.3507 - val_acc: 0.9049\n",
      "Epoch 92/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9609Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4239 - acc: 0.8872\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1079 - acc: 0.9609 - val_loss: 0.4318 - val_acc: 0.8872\n",
      "Epoch 93/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9614Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2307 - acc: 0.8829\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.1083 - acc: 0.9615 - val_loss: 0.4456 - val_acc: 0.8829\n",
      "Epoch 94/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9628Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.4247 - acc: 0.8860\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1071 - acc: 0.9628 - val_loss: 0.4287 - val_acc: 0.8860\n",
      "Epoch 95/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9619Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2623 - acc: 0.8915\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1066 - acc: 0.9619 - val_loss: 0.4034 - val_acc: 0.8915\n",
      "Epoch 96/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9643Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.3176 - acc: 0.8927\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1020 - acc: 0.9643 - val_loss: 0.4108 - val_acc: 0.8927\n",
      "Epoch 97/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9643Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.4375 - acc: 0.9007\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1021 - acc: 0.9643 - val_loss: 0.3516 - val_acc: 0.9007\n",
      "Epoch 98/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9625Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2799 - acc: 0.8886\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1012 - acc: 0.9625 - val_loss: 0.4387 - val_acc: 0.8886\n",
      "Epoch 99/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9610Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.3715 - acc: 0.9005\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.1062 - acc: 0.9610 - val_loss: 0.3770 - val_acc: 0.9005\n",
      "Epoch 100/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9651Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2092 - acc: 0.9030\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0990 - acc: 0.9651 - val_loss: 0.3550 - val_acc: 0.9030\n",
      "Epoch 101/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9658Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3279 - acc: 0.9020\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0962 - acc: 0.9657 - val_loss: 0.3614 - val_acc: 0.9020\n",
      "Epoch 102/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9666Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 338us/sample - loss: 0.6647 - acc: 0.8811\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0951 - acc: 0.9666 - val_loss: 0.4777 - val_acc: 0.8811\n",
      "Epoch 103/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9651Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.2073 - acc: 0.9033\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0971 - acc: 0.9651 - val_loss: 0.3907 - val_acc: 0.9033\n",
      "Epoch 104/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9675Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3069 - acc: 0.9048\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0931 - acc: 0.9675 - val_loss: 0.3598 - val_acc: 0.9048\n",
      "Epoch 105/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9662Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.3901 - acc: 0.8884\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0972 - acc: 0.9662 - val_loss: 0.4545 - val_acc: 0.8884\n",
      "Epoch 106/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9668Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2916 - acc: 0.8987\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0951 - acc: 0.9668 - val_loss: 0.3866 - val_acc: 0.8987\n",
      "Epoch 107/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9681Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.2595 - acc: 0.8966\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0915 - acc: 0.9681 - val_loss: 0.4119 - val_acc: 0.8966\n",
      "Epoch 108/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9674Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2969 - acc: 0.9051\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0917 - acc: 0.9673 - val_loss: 0.3713 - val_acc: 0.9051\n",
      "Epoch 109/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9671Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.3588 - acc: 0.8782\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0909 - acc: 0.9671 - val_loss: 0.5313 - val_acc: 0.8782\n",
      "Epoch 110/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9687Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2582 - acc: 0.8942\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0902 - acc: 0.9687 - val_loss: 0.4131 - val_acc: 0.8942\n",
      "Epoch 111/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9692Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.3610 - acc: 0.8958\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0875 - acc: 0.9692 - val_loss: 0.4062 - val_acc: 0.8958\n",
      "Epoch 112/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9691Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.5092 - acc: 0.9043\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0874 - acc: 0.9691 - val_loss: 0.3669 - val_acc: 0.9043\n",
      "Epoch 113/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9683Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 342us/sample - loss: 0.4200 - acc: 0.8984\n",
      "391/390 [==============================] - 69s 175ms/step - loss: 0.0892 - acc: 0.9684 - val_loss: 0.4007 - val_acc: 0.8984\n",
      "Epoch 114/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9660Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.5627 - acc: 0.8716\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.0922 - acc: 0.9660 - val_loss: 0.5331 - val_acc: 0.8716\n",
      "Epoch 115/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9679Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.3260 - acc: 0.8959\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0899 - acc: 0.9679 - val_loss: 0.4010 - val_acc: 0.8959\n",
      "Epoch 116/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9697Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2590 - acc: 0.9053\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0834 - acc: 0.9697 - val_loss: 0.3746 - val_acc: 0.9053\n",
      "Epoch 117/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9696Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2556 - acc: 0.9006\n",
      "391/390 [==============================] - 67s 173ms/step - loss: 0.0850 - acc: 0.9696 - val_loss: 0.3733 - val_acc: 0.9006\n",
      "Epoch 118/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9688Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2765 - acc: 0.9013\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0846 - acc: 0.9688 - val_loss: 0.4118 - val_acc: 0.9013\n",
      "Epoch 119/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9697Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3051 - acc: 0.9015\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0834 - acc: 0.9697 - val_loss: 0.3926 - val_acc: 0.9015\n",
      "Epoch 120/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9706Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.1941 - acc: 0.9084\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0841 - acc: 0.9706 - val_loss: 0.3621 - val_acc: 0.9084\n",
      "Epoch 121/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9724Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2898 - acc: 0.8771\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0783 - acc: 0.9724 - val_loss: 0.5488 - val_acc: 0.8771\n",
      "Epoch 122/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9712Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2611 - acc: 0.8898\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0825 - acc: 0.9711 - val_loss: 0.4611 - val_acc: 0.8898\n",
      "Epoch 123/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9705Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3261 - acc: 0.8831\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0828 - acc: 0.9704 - val_loss: 0.4872 - val_acc: 0.8831\n",
      "Epoch 124/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9723Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.4722 - acc: 0.9011\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0807 - acc: 0.9723 - val_loss: 0.4257 - val_acc: 0.9011\n",
      "Epoch 125/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9705Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.4419 - acc: 0.8861\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0816 - acc: 0.9705 - val_loss: 0.4865 - val_acc: 0.8861\n",
      "Epoch 126/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9724Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.3348 - acc: 0.9087\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0770 - acc: 0.9724 - val_loss: 0.3887 - val_acc: 0.9087\n",
      "Epoch 127/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9712Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 342us/sample - loss: 0.2405 - acc: 0.9016\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.0816 - acc: 0.9712 - val_loss: 0.3975 - val_acc: 0.9016\n",
      "Epoch 128/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9726Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 338us/sample - loss: 0.2721 - acc: 0.8904\n",
      "391/390 [==============================] - 69s 175ms/step - loss: 0.0767 - acc: 0.9726 - val_loss: 0.4798 - val_acc: 0.8904\n",
      "Epoch 129/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9722Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2263 - acc: 0.9065\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0788 - acc: 0.9722 - val_loss: 0.3674 - val_acc: 0.9065\n",
      "Epoch 130/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9719Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.3115 - acc: 0.8945\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0772 - acc: 0.9720 - val_loss: 0.4335 - val_acc: 0.8945\n",
      "Epoch 131/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9717Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2449 - acc: 0.9112\n",
      "391/390 [==============================] - 67s 173ms/step - loss: 0.0789 - acc: 0.9716 - val_loss: 0.3587 - val_acc: 0.9112\n",
      "Epoch 132/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9733Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2498 - acc: 0.8987\n",
      "391/390 [==============================] - 67s 173ms/step - loss: 0.0723 - acc: 0.9733 - val_loss: 0.4305 - val_acc: 0.8987\n",
      "Epoch 133/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9726Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2946 - acc: 0.9123\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0768 - acc: 0.9726 - val_loss: 0.3468 - val_acc: 0.9123\n",
      "Epoch 134/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9743Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.2516 - acc: 0.9107\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0717 - acc: 0.9743 - val_loss: 0.3725 - val_acc: 0.9107\n",
      "Epoch 135/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9742Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3386 - acc: 0.8978\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0730 - acc: 0.9742 - val_loss: 0.4258 - val_acc: 0.8978\n",
      "Epoch 136/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9755Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.3485 - acc: 0.9054\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0699 - acc: 0.9755 - val_loss: 0.3810 - val_acc: 0.9054\n",
      "Epoch 137/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9737Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3418 - acc: 0.9075\n",
      "391/390 [==============================] - 67s 173ms/step - loss: 0.0734 - acc: 0.9736 - val_loss: 0.3712 - val_acc: 0.9075\n",
      "Epoch 138/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9740Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3075 - acc: 0.9015\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0742 - acc: 0.9740 - val_loss: 0.4090 - val_acc: 0.9015\n",
      "Epoch 139/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9752Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.1869 - acc: 0.9127\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0700 - acc: 0.9751 - val_loss: 0.3595 - val_acc: 0.9127\n",
      "Epoch 140/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9749Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.2199 - acc: 0.8979\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0708 - acc: 0.9748 - val_loss: 0.4145 - val_acc: 0.8979\n",
      "Epoch 141/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9741Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2320 - acc: 0.8981\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0737 - acc: 0.9741 - val_loss: 0.4266 - val_acc: 0.8981\n",
      "Epoch 142/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9754Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.2246 - acc: 0.9039\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0698 - acc: 0.9754 - val_loss: 0.4070 - val_acc: 0.9039\n",
      "Epoch 143/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9747Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 0.5342 - acc: 0.8727\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0726 - acc: 0.9747 - val_loss: 0.6029 - val_acc: 0.8727\n",
      "Epoch 144/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9762Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 4s 371us/sample - loss: 0.3058 - acc: 0.8877\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.0683 - acc: 0.9762 - val_loss: 0.4855 - val_acc: 0.8877\n",
      "Epoch 145/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9758Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.1952 - acc: 0.9113\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0696 - acc: 0.9758 - val_loss: 0.3784 - val_acc: 0.9113\n",
      "Epoch 146/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9749Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.1981 - acc: 0.9078\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0716 - acc: 0.9749 - val_loss: 0.3762 - val_acc: 0.9078\n",
      "Epoch 147/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9769Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.2515 - acc: 0.8977\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0667 - acc: 0.9768 - val_loss: 0.4278 - val_acc: 0.8977\n",
      "Epoch 148/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9765Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.2373 - acc: 0.8899\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0672 - acc: 0.9766 - val_loss: 0.4539 - val_acc: 0.8899\n",
      "Epoch 149/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9768Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2645 - acc: 0.9022\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0673 - acc: 0.9769 - val_loss: 0.4130 - val_acc: 0.9022\n",
      "Epoch 150/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9774Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.1753 - acc: 0.9163\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0657 - acc: 0.9775 - val_loss: 0.3368 - val_acc: 0.9163\n",
      "Epoch 151/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9770Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.5023 - acc: 0.8871\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0655 - acc: 0.9770 - val_loss: 0.5098 - val_acc: 0.8871\n",
      "Epoch 152/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9763Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4149 - acc: 0.8847\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0669 - acc: 0.9763 - val_loss: 0.5128 - val_acc: 0.8847\n",
      "Epoch 153/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9761Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.2770 - acc: 0.8997\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0679 - acc: 0.9760 - val_loss: 0.4215 - val_acc: 0.8997\n",
      "Epoch 154/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9779Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4149 - acc: 0.9091\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0640 - acc: 0.9779 - val_loss: 0.3968 - val_acc: 0.9091\n",
      "Epoch 155/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9759Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 342us/sample - loss: 0.3687 - acc: 0.8801\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0665 - acc: 0.9758 - val_loss: 0.5243 - val_acc: 0.8801\n",
      "Epoch 156/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9777Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2952 - acc: 0.9072\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0621 - acc: 0.9777 - val_loss: 0.4328 - val_acc: 0.9072\n",
      "Epoch 157/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9785Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3168 - acc: 0.8917\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0611 - acc: 0.9784 - val_loss: 0.4697 - val_acc: 0.8917\n",
      "Epoch 158/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9758Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.4888 - acc: 0.8917\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0657 - acc: 0.9758 - val_loss: 0.5031 - val_acc: 0.8917\n",
      "Epoch 159/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9786Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2032 - acc: 0.9108\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0619 - acc: 0.9786 - val_loss: 0.3874 - val_acc: 0.9108\n",
      "Epoch 160/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9760Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 0.3402 - acc: 0.9066\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.0669 - acc: 0.9760 - val_loss: 0.4221 - val_acc: 0.9066\n",
      "Epoch 161/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9777Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.5949 - acc: 0.8899\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0624 - acc: 0.9776 - val_loss: 0.5035 - val_acc: 0.8899\n",
      "Epoch 162/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9786Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2174 - acc: 0.9066\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0597 - acc: 0.9786 - val_loss: 0.3980 - val_acc: 0.9066\n",
      "Epoch 163/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9785Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2648 - acc: 0.9141\n",
      "391/390 [==============================] - 67s 173ms/step - loss: 0.0624 - acc: 0.9785 - val_loss: 0.3614 - val_acc: 0.9141\n",
      "Epoch 164/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9790Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2386 - acc: 0.9046\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0602 - acc: 0.9791 - val_loss: 0.4212 - val_acc: 0.9046\n",
      "Epoch 165/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9774Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3768 - acc: 0.8983\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0627 - acc: 0.9774 - val_loss: 0.4579 - val_acc: 0.8983\n",
      "Epoch 166/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9788Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3056 - acc: 0.8994\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0615 - acc: 0.9789 - val_loss: 0.4470 - val_acc: 0.8994\n",
      "Epoch 167/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9783Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.2456 - acc: 0.8994\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0610 - acc: 0.9783 - val_loss: 0.4510 - val_acc: 0.8994\n",
      "Epoch 168/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9785Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2285 - acc: 0.9135\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0613 - acc: 0.9785 - val_loss: 0.3645 - val_acc: 0.9135\n",
      "Epoch 169/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9791Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.6568 - acc: 0.8866\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0599 - acc: 0.9792 - val_loss: 0.5635 - val_acc: 0.8866\n",
      "Epoch 170/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9798Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.2769 - acc: 0.9092\n",
      "391/390 [==============================] - 67s 171ms/step - loss: 0.0574 - acc: 0.9798 - val_loss: 0.4101 - val_acc: 0.9092\n",
      "Epoch 171/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9787Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.5186 - acc: 0.9053\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0586 - acc: 0.9787 - val_loss: 0.4069 - val_acc: 0.9053\n",
      "Epoch 172/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9787Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3869 - acc: 0.8811\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0611 - acc: 0.9786 - val_loss: 0.5319 - val_acc: 0.8811\n",
      "Epoch 173/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9788Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3471 - acc: 0.9096\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0598 - acc: 0.9788 - val_loss: 0.3706 - val_acc: 0.9096\n",
      "Epoch 174/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9786Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3825 - acc: 0.9108\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0595 - acc: 0.9787 - val_loss: 0.3956 - val_acc: 0.9108\n",
      "Epoch 175/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9796Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3469 - acc: 0.9011\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0567 - acc: 0.9796 - val_loss: 0.4197 - val_acc: 0.9011\n",
      "Epoch 176/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9798Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.2543 - acc: 0.9139\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0569 - acc: 0.9798 - val_loss: 0.3742 - val_acc: 0.9139\n",
      "Epoch 177/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9803Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2645 - acc: 0.8987\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0561 - acc: 0.9804 - val_loss: 0.4642 - val_acc: 0.8987\n",
      "Epoch 178/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9803Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2681 - acc: 0.9077\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0560 - acc: 0.9803 - val_loss: 0.4024 - val_acc: 0.9077\n",
      "Epoch 179/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9798Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2538 - acc: 0.9055\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0569 - acc: 0.9798 - val_loss: 0.4078 - val_acc: 0.9055\n",
      "Epoch 180/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9814Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.2868 - acc: 0.8885\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0544 - acc: 0.9813 - val_loss: 0.5212 - val_acc: 0.8885\n",
      "Epoch 181/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9805Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.4897 - acc: 0.8901\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0551 - acc: 0.9805 - val_loss: 0.5214 - val_acc: 0.8901\n",
      "Epoch 182/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9820Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.4202 - acc: 0.9066\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0505 - acc: 0.9820 - val_loss: 0.4125 - val_acc: 0.9066\n",
      "Epoch 183/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9801Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2143 - acc: 0.9101\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0561 - acc: 0.9801 - val_loss: 0.4078 - val_acc: 0.9101\n",
      "Epoch 184/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9814Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3030 - acc: 0.9028\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0536 - acc: 0.9814 - val_loss: 0.4657 - val_acc: 0.9028\n",
      "Epoch 185/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9803Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.2503 - acc: 0.9031\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0565 - acc: 0.9803 - val_loss: 0.4624 - val_acc: 0.9031\n",
      "Epoch 186/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9815Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.3124 - acc: 0.9064\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0531 - acc: 0.9815 - val_loss: 0.4146 - val_acc: 0.9064\n",
      "Epoch 187/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9806Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2530 - acc: 0.8991\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0566 - acc: 0.9806 - val_loss: 0.4579 - val_acc: 0.8991\n",
      "Epoch 188/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9815Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2192 - acc: 0.9052\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0529 - acc: 0.9815 - val_loss: 0.4128 - val_acc: 0.9052\n",
      "Epoch 189/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9832Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.2395 - acc: 0.9128\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0497 - acc: 0.9832 - val_loss: 0.3875 - val_acc: 0.9128\n",
      "Epoch 190/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9810Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4854 - acc: 0.8998\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0547 - acc: 0.9809 - val_loss: 0.4558 - val_acc: 0.8998\n",
      "Epoch 191/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9803Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2623 - acc: 0.8980\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0571 - acc: 0.9803 - val_loss: 0.4292 - val_acc: 0.8980\n",
      "Epoch 192/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9820Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.5556 - acc: 0.9079\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0508 - acc: 0.9820 - val_loss: 0.4002 - val_acc: 0.9079\n",
      "Epoch 193/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9829Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.4262 - acc: 0.8974\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0504 - acc: 0.9828 - val_loss: 0.4576 - val_acc: 0.8974\n",
      "Epoch 194/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9803Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.2308 - acc: 0.9088\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0556 - acc: 0.9803 - val_loss: 0.4170 - val_acc: 0.9088\n",
      "Epoch 195/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9821Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2311 - acc: 0.9061\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0517 - acc: 0.9821 - val_loss: 0.4162 - val_acc: 0.9061\n",
      "Epoch 196/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9811Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.3200 - acc: 0.8887\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0540 - acc: 0.9811 - val_loss: 0.5003 - val_acc: 0.8887\n",
      "Epoch 197/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9820Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.3042 - acc: 0.9078\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0509 - acc: 0.9820 - val_loss: 0.4120 - val_acc: 0.9078\n",
      "Epoch 198/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9826Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.5716 - acc: 0.9068\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0526 - acc: 0.9825 - val_loss: 0.4189 - val_acc: 0.9068\n",
      "Epoch 199/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9823Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.3280 - acc: 0.9037\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0513 - acc: 0.9823 - val_loss: 0.4467 - val_acc: 0.9037\n",
      "Epoch 200/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9823Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 4s 355us/sample - loss: 0.3409 - acc: 0.8968\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0500 - acc: 0.9823 - val_loss: 0.4728 - val_acc: 0.8968\n",
      "Epoch 201/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9824Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.2546 - acc: 0.9101\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0526 - acc: 0.9823 - val_loss: 0.3783 - val_acc: 0.9101\n",
      "Epoch 202/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9827Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.2196 - acc: 0.9118\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0489 - acc: 0.9827 - val_loss: 0.4014 - val_acc: 0.9118\n",
      "Epoch 203/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9829Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.2650 - acc: 0.9038\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0478 - acc: 0.9829 - val_loss: 0.4300 - val_acc: 0.9038\n",
      "Epoch 204/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9826Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 338us/sample - loss: 0.3652 - acc: 0.8763\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0481 - acc: 0.9825 - val_loss: 0.5940 - val_acc: 0.8763\n",
      "Epoch 205/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9831Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3242 - acc: 0.9019\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0480 - acc: 0.9831 - val_loss: 0.4712 - val_acc: 0.9019\n",
      "Epoch 206/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9815Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3140 - acc: 0.9062\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0524 - acc: 0.9815 - val_loss: 0.4457 - val_acc: 0.9062\n",
      "Epoch 207/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9839Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.3176 - acc: 0.9139\n",
      "391/390 [==============================] - 67s 173ms/step - loss: 0.0466 - acc: 0.9839 - val_loss: 0.4014 - val_acc: 0.9139\n",
      "Epoch 208/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9820Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.3530 - acc: 0.9016\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0526 - acc: 0.9820 - val_loss: 0.4682 - val_acc: 0.9016\n",
      "Epoch 209/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9831Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3131 - acc: 0.9053\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0500 - acc: 0.9832 - val_loss: 0.4359 - val_acc: 0.9053\n",
      "Epoch 210/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9826Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.2573 - acc: 0.9128\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0482 - acc: 0.9826 - val_loss: 0.3801 - val_acc: 0.9128\n",
      "Epoch 211/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9835Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3132 - acc: 0.9161\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0474 - acc: 0.9835 - val_loss: 0.3800 - val_acc: 0.9161\n",
      "Epoch 212/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9838Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.2543 - acc: 0.9054\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0476 - acc: 0.9838 - val_loss: 0.4420 - val_acc: 0.9054\n",
      "Epoch 213/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9836Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.2110 - acc: 0.9065\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0455 - acc: 0.9836 - val_loss: 0.4090 - val_acc: 0.9065\n",
      "Epoch 214/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9826Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.2440 - acc: 0.9092\n",
      "391/390 [==============================] - 67s 171ms/step - loss: 0.0502 - acc: 0.9826 - val_loss: 0.4166 - val_acc: 0.9092\n",
      "Epoch 215/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9818Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.2066 - acc: 0.9124\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0507 - acc: 0.9818 - val_loss: 0.3937 - val_acc: 0.9124\n",
      "Epoch 216/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9842Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2767 - acc: 0.9010\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0458 - acc: 0.9842 - val_loss: 0.4680 - val_acc: 0.9010\n",
      "Epoch 217/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9838Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.2739 - acc: 0.9098\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0482 - acc: 0.9838 - val_loss: 0.4210 - val_acc: 0.9098\n",
      "Epoch 218/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9846Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.2966 - acc: 0.9095\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0443 - acc: 0.9846 - val_loss: 0.4340 - val_acc: 0.9095\n",
      "Epoch 219/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9838Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.2462 - acc: 0.9065\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0451 - acc: 0.9838 - val_loss: 0.4023 - val_acc: 0.9065\n",
      "Epoch 220/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9840Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.2859 - acc: 0.8996\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0471 - acc: 0.9840 - val_loss: 0.4776 - val_acc: 0.8996\n",
      "Epoch 221/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9830Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2901 - acc: 0.8978\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0470 - acc: 0.9830 - val_loss: 0.4905 - val_acc: 0.8978\n",
      "Epoch 222/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9845Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2757 - acc: 0.9056\n",
      "391/390 [==============================] - 67s 173ms/step - loss: 0.0455 - acc: 0.9845 - val_loss: 0.4395 - val_acc: 0.9056\n",
      "Epoch 223/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9841Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.2064 - acc: 0.9172\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0454 - acc: 0.9841 - val_loss: 0.3814 - val_acc: 0.9172\n",
      "Epoch 224/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9841Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.5371 - acc: 0.8801\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0451 - acc: 0.9841 - val_loss: 0.6431 - val_acc: 0.8801\n",
      "Epoch 225/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9839Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.2364 - acc: 0.9054\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0459 - acc: 0.9839 - val_loss: 0.4498 - val_acc: 0.9054\n",
      "Epoch 226/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9835Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.2151 - acc: 0.9123\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0471 - acc: 0.9835 - val_loss: 0.4188 - val_acc: 0.9123\n",
      "Epoch 227/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9847Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.2925 - acc: 0.9043\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0440 - acc: 0.9847 - val_loss: 0.4697 - val_acc: 0.9043\n",
      "Epoch 228/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9842Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2539 - acc: 0.9038\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0431 - acc: 0.9841 - val_loss: 0.4629 - val_acc: 0.9038\n",
      "Epoch 229/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9846Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.2666 - acc: 0.9046\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0442 - acc: 0.9846 - val_loss: 0.4860 - val_acc: 0.9046\n",
      "Epoch 230/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9840Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2359 - acc: 0.9025\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0459 - acc: 0.9840 - val_loss: 0.4643 - val_acc: 0.9025\n",
      "Epoch 231/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9827Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.3427 - acc: 0.9050\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0477 - acc: 0.9828 - val_loss: 0.4420 - val_acc: 0.9050\n",
      "Epoch 232/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9852Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.2556 - acc: 0.9009\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0434 - acc: 0.9851 - val_loss: 0.4807 - val_acc: 0.9009\n",
      "Epoch 233/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9840Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.5184 - acc: 0.8916\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0459 - acc: 0.9840 - val_loss: 0.5658 - val_acc: 0.8916\n",
      "Epoch 234/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9839Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.2761 - acc: 0.9111\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0467 - acc: 0.9839 - val_loss: 0.4064 - val_acc: 0.9111\n",
      "Epoch 235/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9840Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2652 - acc: 0.9043\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0435 - acc: 0.9840 - val_loss: 0.4536 - val_acc: 0.9043\n",
      "Epoch 236/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9852Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.5414 - acc: 0.8865\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0432 - acc: 0.9853 - val_loss: 0.5819 - val_acc: 0.8865\n",
      "Epoch 237/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9856Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.2304 - acc: 0.9084\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0421 - acc: 0.9856 - val_loss: 0.4410 - val_acc: 0.9084\n",
      "Epoch 238/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9838Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2412 - acc: 0.9016\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0454 - acc: 0.9838 - val_loss: 0.4652 - val_acc: 0.9016\n",
      "Epoch 239/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9836Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2617 - acc: 0.9061\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0473 - acc: 0.9835 - val_loss: 0.4380 - val_acc: 0.9061\n",
      "Epoch 240/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9852Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.3589 - acc: 0.8978\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0417 - acc: 0.9852 - val_loss: 0.5011 - val_acc: 0.8978\n",
      "Epoch 241/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9857Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2513 - acc: 0.9074\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0415 - acc: 0.9856 - val_loss: 0.4401 - val_acc: 0.9074\n",
      "Epoch 242/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9843Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3392 - acc: 0.9013\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.0445 - acc: 0.9842 - val_loss: 0.4887 - val_acc: 0.9013\n",
      "Epoch 243/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9876Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3148 - acc: 0.9007\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0375 - acc: 0.9876 - val_loss: 0.5107 - val_acc: 0.9007\n",
      "Epoch 244/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9842Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.4286 - acc: 0.9069\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0461 - acc: 0.9843 - val_loss: 0.4298 - val_acc: 0.9069\n",
      "Epoch 245/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9850Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3057 - acc: 0.9044\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0424 - acc: 0.9850 - val_loss: 0.4653 - val_acc: 0.9044\n",
      "Epoch 246/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9851Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.6247 - acc: 0.9014\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0422 - acc: 0.9851 - val_loss: 0.4660 - val_acc: 0.9014\n",
      "Epoch 247/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9855Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3149 - acc: 0.9053\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0408 - acc: 0.9855 - val_loss: 0.4631 - val_acc: 0.9053\n",
      "Epoch 248/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9851Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.2227 - acc: 0.9076\n",
      "391/390 [==============================] - 67s 171ms/step - loss: 0.0425 - acc: 0.9852 - val_loss: 0.4374 - val_acc: 0.9076\n",
      "Epoch 249/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9851Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.4410 - acc: 0.9008\n",
      "391/390 [==============================] - 67s 171ms/step - loss: 0.0421 - acc: 0.9851 - val_loss: 0.4845 - val_acc: 0.9008\n",
      "Epoch 250/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9855Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.3656 - acc: 0.9055\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0412 - acc: 0.9855 - val_loss: 0.4556 - val_acc: 0.9055\n",
      "Epoch 251/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9853Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.2157 - acc: 0.9115\n",
      "391/390 [==============================] - 67s 171ms/step - loss: 0.0428 - acc: 0.9853 - val_loss: 0.4074 - val_acc: 0.9115\n",
      "Epoch 252/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9855Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3096 - acc: 0.9080\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0405 - acc: 0.9855 - val_loss: 0.4598 - val_acc: 0.9080\n",
      "Epoch 253/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9863Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2267 - acc: 0.9116\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0400 - acc: 0.9864 - val_loss: 0.4337 - val_acc: 0.9116\n",
      "Epoch 254/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9851Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3229 - acc: 0.9062\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0426 - acc: 0.9851 - val_loss: 0.4560 - val_acc: 0.9062\n",
      "Epoch 255/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9858Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2452 - acc: 0.9049\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0405 - acc: 0.9859 - val_loss: 0.4617 - val_acc: 0.9049\n",
      "Epoch 256/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9861Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.2025 - acc: 0.9158\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0413 - acc: 0.9861 - val_loss: 0.3942 - val_acc: 0.9158\n",
      "Epoch 257/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9867Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4118 - acc: 0.9042\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 0.0399 - acc: 0.9867 - val_loss: 0.4643 - val_acc: 0.9042\n",
      "Epoch 258/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9847Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 339us/sample - loss: 0.3772 - acc: 0.8950\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 0.0430 - acc: 0.9847 - val_loss: 0.5159 - val_acc: 0.8950\n",
      "Epoch 259/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9867Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 344us/sample - loss: 0.3656 - acc: 0.9069\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.0383 - acc: 0.9867 - val_loss: 0.4688 - val_acc: 0.9069\n",
      "Epoch 260/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9864Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 343us/sample - loss: 0.2981 - acc: 0.9098\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0394 - acc: 0.9863 - val_loss: 0.4331 - val_acc: 0.9098\n",
      "Epoch 261/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9853Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 345us/sample - loss: 0.2553 - acc: 0.9166\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0423 - acc: 0.9853 - val_loss: 0.3970 - val_acc: 0.9166\n",
      "Epoch 262/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9857Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 344us/sample - loss: 0.3118 - acc: 0.9085\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0406 - acc: 0.9857 - val_loss: 0.4350 - val_acc: 0.9085\n",
      "Epoch 263/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9864Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 345us/sample - loss: 0.2930 - acc: 0.9077\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0391 - acc: 0.9864 - val_loss: 0.4406 - val_acc: 0.9077\n",
      "Epoch 264/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9863Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 341us/sample - loss: 0.2182 - acc: 0.9145\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0397 - acc: 0.9862 - val_loss: 0.4195 - val_acc: 0.9145\n",
      "Epoch 265/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9861Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 344us/sample - loss: 0.2796 - acc: 0.9077\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0391 - acc: 0.9862 - val_loss: 0.4607 - val_acc: 0.9077\n",
      "Epoch 266/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9866Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 345us/sample - loss: 0.2184 - acc: 0.9070\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0395 - acc: 0.9866 - val_loss: 0.4221 - val_acc: 0.9070\n",
      "Epoch 267/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9864Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 343us/sample - loss: 0.2555 - acc: 0.9133\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0391 - acc: 0.9864 - val_loss: 0.4052 - val_acc: 0.9133\n",
      "Epoch 268/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9867Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3165 - acc: 0.9082\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.0379 - acc: 0.9867 - val_loss: 0.4448 - val_acc: 0.9082\n",
      "Epoch 269/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9870Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.2067 - acc: 0.9147\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 0.0378 - acc: 0.9870 - val_loss: 0.3931 - val_acc: 0.9147\n",
      "Epoch 270/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9862Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.4779 - acc: 0.9048\n",
      "391/390 [==============================] - 68s 175ms/step - loss: 0.0385 - acc: 0.9862 - val_loss: 0.4834 - val_acc: 0.9048\n",
      "Epoch 271/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9875Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 346us/sample - loss: 0.2808 - acc: 0.9059\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0373 - acc: 0.9875 - val_loss: 0.4710 - val_acc: 0.9059\n",
      "Epoch 272/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9859Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 344us/sample - loss: 0.2418 - acc: 0.9139\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0408 - acc: 0.9859 - val_loss: 0.4033 - val_acc: 0.9139\n",
      "Epoch 273/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9862Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 346us/sample - loss: 0.3419 - acc: 0.9142\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0398 - acc: 0.9862 - val_loss: 0.4278 - val_acc: 0.9142\n",
      "Epoch 274/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9863Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 344us/sample - loss: 0.3107 - acc: 0.9010\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0379 - acc: 0.9863 - val_loss: 0.4926 - val_acc: 0.9010\n",
      "Epoch 275/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9872Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 344us/sample - loss: 0.2765 - acc: 0.9111\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0373 - acc: 0.9872 - val_loss: 0.4311 - val_acc: 0.9111\n",
      "Epoch 276/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9875Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 348us/sample - loss: 0.2709 - acc: 0.9121\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0351 - acc: 0.9875 - val_loss: 0.4221 - val_acc: 0.9121\n",
      "Epoch 277/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9864Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 347us/sample - loss: 0.4549 - acc: 0.9103\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0375 - acc: 0.9864 - val_loss: 0.4319 - val_acc: 0.9103\n",
      "Epoch 278/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9868Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 349us/sample - loss: 0.2455 - acc: 0.8987\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.0380 - acc: 0.9868 - val_loss: 0.4732 - val_acc: 0.8987\n",
      "Epoch 279/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9867Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 343us/sample - loss: 0.2755 - acc: 0.9014\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0378 - acc: 0.9867 - val_loss: 0.4916 - val_acc: 0.9014\n",
      "Epoch 280/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9881Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 348us/sample - loss: 0.4117 - acc: 0.9114\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0355 - acc: 0.9881 - val_loss: 0.4344 - val_acc: 0.9114\n",
      "Epoch 281/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9868Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 348us/sample - loss: 0.2529 - acc: 0.9059\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0380 - acc: 0.9868 - val_loss: 0.4551 - val_acc: 0.9059\n",
      "Epoch 282/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9868Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 345us/sample - loss: 0.3149 - acc: 0.9118\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.0363 - acc: 0.9869 - val_loss: 0.4407 - val_acc: 0.9118\n",
      "Epoch 283/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9870Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 345us/sample - loss: 0.2503 - acc: 0.9173\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.0358 - acc: 0.9871 - val_loss: 0.4180 - val_acc: 0.9173\n",
      "Epoch 284/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9874Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 347us/sample - loss: 0.4867 - acc: 0.9080\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.0383 - acc: 0.9875 - val_loss: 0.4521 - val_acc: 0.9080\n",
      "Epoch 285/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9871Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 345us/sample - loss: 0.2929 - acc: 0.9104\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0375 - acc: 0.9871 - val_loss: 0.4483 - val_acc: 0.9104\n",
      "Epoch 286/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9881Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 347us/sample - loss: 0.3408 - acc: 0.9182\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0359 - acc: 0.9881 - val_loss: 0.3899 - val_acc: 0.9182\n",
      "Epoch 287/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9874Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 345us/sample - loss: 0.2385 - acc: 0.9114\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0368 - acc: 0.9874 - val_loss: 0.4374 - val_acc: 0.9114\n",
      "Epoch 288/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9871Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 348us/sample - loss: 0.3641 - acc: 0.9110\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.0365 - acc: 0.9871 - val_loss: 0.4455 - val_acc: 0.9110\n",
      "Epoch 289/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9868Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 348us/sample - loss: 0.3331 - acc: 0.9073\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0375 - acc: 0.9868 - val_loss: 0.4537 - val_acc: 0.9073\n",
      "Epoch 290/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9884Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 346us/sample - loss: 0.3222 - acc: 0.9067\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0342 - acc: 0.9883 - val_loss: 0.4422 - val_acc: 0.9067\n",
      "Epoch 291/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9872Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 344us/sample - loss: 0.2501 - acc: 0.9033\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0376 - acc: 0.9872 - val_loss: 0.4894 - val_acc: 0.9033\n",
      "Epoch 292/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9881Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 346us/sample - loss: 0.4114 - acc: 0.9097\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.0339 - acc: 0.9881 - val_loss: 0.4619 - val_acc: 0.9097\n",
      "Epoch 293/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9872Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 348us/sample - loss: 0.2341 - acc: 0.9057\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.0388 - acc: 0.9872 - val_loss: 0.4554 - val_acc: 0.9057\n",
      "Epoch 294/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9881Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 4s 350us/sample - loss: 0.2927 - acc: 0.9047\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.0345 - acc: 0.9881 - val_loss: 0.4910 - val_acc: 0.9047\n",
      "Epoch 295/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9873Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 346us/sample - loss: 0.4016 - acc: 0.9131\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.0368 - acc: 0.9873 - val_loss: 0.4055 - val_acc: 0.9131\n",
      "Epoch 296/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9876Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 345us/sample - loss: 0.2010 - acc: 0.9217\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0373 - acc: 0.9876 - val_loss: 0.3906 - val_acc: 0.9217\n",
      "Epoch 297/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9866Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 343us/sample - loss: 0.2989 - acc: 0.9014\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.0383 - acc: 0.9866 - val_loss: 0.5025 - val_acc: 0.9014\n",
      "Epoch 298/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9873Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 343us/sample - loss: 0.2555 - acc: 0.9031\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0362 - acc: 0.9873 - val_loss: 0.4706 - val_acc: 0.9031\n",
      "Epoch 299/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9888Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 343us/sample - loss: 0.2683 - acc: 0.9130\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0327 - acc: 0.9888 - val_loss: 0.4708 - val_acc: 0.9130\n",
      "Epoch 300/300\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9879Epoch 1/300\n",
      "10000/390 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 345us/sample - loss: 0.2266 - acc: 0.9112\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.0349 - acc: 0.9879 - val_loss: 0.4413 - val_acc: 0.9112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe40e6d7908>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model_3.fit_generator(image_gen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 300, validation_data =(X_test,y_test),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "otze6foaZwi6",
    "outputId": "f9713a95-4bce-424e-d036-39ee496731d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 540us/sample - loss: 0.4462 - acc: 0.9112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4461723472420126, 0.9112]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AqQKuySlepzf"
   },
   "source": [
    " this model got 91.1% test accuracy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DenseNet_cifar10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
